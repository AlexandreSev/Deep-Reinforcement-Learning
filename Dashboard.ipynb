{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dashboard for DRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import bokeh\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models.widgets import Panel, Tabs\n",
    "from bokeh.io import output_notebook, show, output_file, reset_output, gridplot, save\n",
    "\n",
    "reset_output()\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, change the working directory in this cell. \n",
    "\n",
    "If you want to have more learners represented, increase the variable n_actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "working_directory = \"/home/alex/Documents/Projet_info/Deep-Reinforcement-Learning/callbacks\"\n",
    "#working_directory = \"/Users/nicolashennetier/Deep-Reinforcement-Learning/callbacks\"\n",
    "n_actors = 1\n",
    "n_plot = 6\n",
    "list_files = [\"rpe.csv\", \"epsilon.csv\", \"lr.csv\", \"rewards.csv\", \"random.csv\", \"diff.csv\", \"action.csv\"]\n",
    "list_titles = [\"Reward per Environment\", \"Epsilon per Environment\", \"Learning Rate per Environment\", \"Reward per Iteration\", \"Randomness\",\"Norm of applied gradients\", \"gnActions taken\"]\n",
    "list_x_labels = [\"Environments\", \"Environments\", \"Environments\", \"Iterations\", \"Iterations\", \"Iterations\", \"Iterations\"]\n",
    "list_y_labels = [\"Reward\", \"Epsilon\", \"Learning Rate\", \"Reward\", \"Random ?\", \"Norm\", \"Action\"]\n",
    "colors = [\"orange\", \"orange\", \"orange\", \"lime\", \"navy\", \"darkred\", \"purple\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reset_output()\n",
    "output_notebook()\n",
    "\n",
    "tabs = []\n",
    "p = []\n",
    "for j in range(n_actors):\n",
    "    p.append([])\n",
    "    for i in range(n_plot):\n",
    "        data = pd.read_csv(pjoin(working_directory, \"actor\"+str(j), list_files[i]), header=None, names=[\"to_plot\"])\n",
    "        if i in [2, 4]:\n",
    "            data[\"data\"] = data[\"to_plot\"].values\n",
    "            data[\"to_plot\"] = np.convolve(data.data, np.ones((100,))/100, mode='same')\n",
    "        p[j].append(figure(title=list_titles[i], width=900, height=350))\n",
    "        p[j][i].grid.grid_line_alpha = 0\n",
    "        p[j][i].xaxis.axis_label = list_x_labels[i]\n",
    "        p[j][i].yaxis.axis_label = list_y_labels[i]\n",
    "        p[j][i].ygrid.band_fill_color = \"olive\"\n",
    "        p[j][i].ygrid.band_fill_alpha = 0.1\n",
    "\n",
    "        p[j][i].line(data.index, data[\"to_plot\"], color=colors[i])\n",
    "    \n",
    "    tabs.append(Panel(child=column(p[j]), title=\"actor\"+str(j)))\n",
    "    \n",
    "p.append([])\n",
    "data = pd.read_csv(pjoin(working_directory, \"tester\", list_files[0]), header=None, names=[\"to_plot\"])\n",
    "p[-1].append(figure(title=list_titles[0], width=900, height=350))\n",
    "p[-1][0].grid.grid_line_alpha = 0\n",
    "p[-1][0].xaxis.axis_label = list_x_labels[0]\n",
    "p[-1][0].yaxis.axis_label = list_y_labels[0]\n",
    "p[-1][0].ygrid.band_fill_color = \"olive\"\n",
    "p[-1][0].ygrid.band_fill_alpha = 0.1\n",
    "p[-1][0].line(data.index, data[\"to_plot\"], color=colors[0])\n",
    "    \n",
    "tabs.append(Panel(child=column(p[-1]), title=\"tester\"))\n",
    "\n",
    "tabs_f = Tabs(tabs=tabs)\n",
    "show(tabs_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study of one learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(pjoin(working_directory, \"actor0\", \"history.csv\"), header=None, names=[\"times\", \"true\", \n",
    "                \"estimated\",\"\", \"reward0\", \"reward1\"],# \"reward2\", \"reward3\", \"reward4\", \"reward5\", \"reward6\", \"reward7\", \"reward8\"], \n",
    "                   sep=\";\", index_col=False)\n",
    "\n",
    "\n",
    "data[\"indic\"] = np.cumsum((data.times == 0).astype(np.int16))\n",
    "true = []\n",
    "\n",
    "for i in np.unique(data.indic):\n",
    "    pseudo_true = data[data.indic == i][\"true\"].values[::-1]\n",
    "    true_temp = [pseudo_true[0]]\n",
    "    for j in range(1, len(pseudo_true)):\n",
    "        true_temp.append(pseudo_true[j] + 0.9 * true_temp[j-1])\n",
    "    true += true_temp[::-1]\n",
    "\n",
    "data[\"true\"] = true\n",
    "nb_env = np.max(data.indic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differences between true and estimated reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_x = np.arange(200)\n",
    "\n",
    "def plot_rewards(x):\n",
    "    p=(figure(title=\"History\", width=900, height=350))\n",
    "    p.grid.grid_line_alpha = 0\n",
    "    p.xaxis.axis_label = \"times\"\n",
    "    p.yaxis.axis_label = \"Rewards\"\n",
    "    p.ygrid.band_fill_color = \"olive\"\n",
    "    p.ygrid.band_fill_alpha = 0.1\n",
    "\n",
    "    n = len(data[data.indic == x][\"true\"].values)\n",
    "\n",
    "    true = np.zeros(200)\n",
    "    true[:n] = data[data.indic == x][\"true\"].values[0:200]\n",
    "\n",
    "    estimated = np.zeros(200)\n",
    "    estimated[:n] = data[data.indic == x][\"estimated\"].values[0:200]\n",
    "\n",
    "    p.line(plot_x, true, color=\"lime\")\n",
    "    p.line(plot_x, estimated, color=\"red\")\n",
    "\n",
    "    show(p)\n",
    "\n",
    "interact(plot_rewards, x=widgets.IntSlider(min=1,max=nb_env,step=1,value=200))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilites/rewards of actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_proba(x):\n",
    "    p=(figure(title=\"History\", width=900, height=350))\n",
    "    p.grid.grid_line_alpha = 0\n",
    "    p.xaxis.axis_label = \"times\"\n",
    "    p.yaxis.axis_label = \"Rewards\"\n",
    "    p.ygrid.band_fill_color = \"olive\"\n",
    "    p.ygrid.band_fill_alpha = 0.1\n",
    "\n",
    "    n = len(data[data.indic == x][\"true\"].values)\n",
    "\n",
    "    reward0 = np.zeros(200)\n",
    "    reward0[:n] = data[data.indic == x][\"reward0\"].values[0:200]\n",
    "\n",
    "    reward1 = np.zeros(200)\n",
    "    reward1[:n] = data[data.indic == x][\"reward1\"].values[0:200]\n",
    "\n",
    "    p.line(plot_x, reward0, color=\"navy\")\n",
    "    p.line(plot_x, reward1, color=\"red\")\n",
    "\n",
    "    show(p)\n",
    "    \n",
    "interact(plot_proba, x=widgets.IntSlider(min=1,max=nb_env,step=1,value=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
